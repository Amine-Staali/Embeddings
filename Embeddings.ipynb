{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOwOwqMqqq-O"
      },
      "source": [
        "# **Static Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDmHxdovqUcd",
        "outputId": "742223b2-d2fc-4ef5-9f13-f3379eff3e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: knowledge, Embedding: [-0.03500008  0.04440337  0.02095337  0.04516044  0.04250155  0.04706714\n",
            " -0.02368221 -0.00351129  0.01467735 -0.02824395  0.05242957 -0.06161352\n",
            "  0.04227901  0.0182151  -0.0308302   0.02748867]\n",
            "Word: is, Embedding: [-0.05573369 -0.04400975  0.0056341   0.03995334 -0.05387305  0.02291086\n",
            "  0.03243677  0.03588711  0.04666824 -0.03854797  0.00691009  0.03779551\n",
            " -0.01775032 -0.03858452 -0.00256389 -0.05230593]\n",
            "Word: power,, Embedding: [-0.00535348  0.01766602  0.03375893  0.0440791  -0.03564451  0.01161762\n",
            "  0.0380554  -0.02998782 -0.01942038  0.04248518  0.01019672  0.00118698\n",
            "  0.02171023  0.00136111  0.06011766  0.03162877]\n",
            "Word: but, Embedding: [-0.00942505  0.01543622 -0.00555017  0.03458539 -0.01714361  0.01412541\n",
            "  0.03409871  0.05216221 -0.00908588 -0.05755089  0.02731595  0.00357366\n",
            "  0.04651193 -0.00508302 -0.01649009 -0.05470631]\n",
            "Word: enthusiasm, Embedding: [ 0.03113786  0.05770715 -0.05098698  0.02809874 -0.02585673  0.00515335\n",
            "  0.05311637 -0.0278886   0.02823438 -0.0424185  -0.02217805  0.05874068\n",
            " -0.00986033  0.00200857 -0.02587894 -0.0480168 ]\n",
            "Word: pulls, Embedding: [ 0.05961324 -0.04574479 -0.01458605 -0.01211088  0.05048398 -0.0370681\n",
            "  0.00028227 -0.02971084 -0.06002219  0.03129558 -0.05474741 -0.02744891\n",
            " -0.00021937 -0.00185113 -0.04788275  0.06009214]\n",
            "Word: the, Embedding: [ 0.01797862  0.00619921 -0.05178259 -0.05905511  0.04569854  0.03168914\n",
            "  0.04223558  0.00476791  0.03969306 -0.02128354 -0.00591501  0.03605358\n",
            " -0.04701024 -0.02460065 -0.04694739 -0.00581276]\n",
            "Word: switch, Embedding: [-0.00335142  0.0014777   0.03189594  0.05630796 -0.05814344 -0.04448006\n",
            "  0.04036795  0.05608118 -0.03134643 -0.02352107  0.04612815 -0.0095842\n",
            " -0.02835383  0.04096282 -0.030376   -0.01135011]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sentence = 'Knowledge is power, but enthusiasm pulls the switch'\n",
        "\n",
        "# Preprocess the sentence\n",
        "words = sentence.lower().split()\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec([words], vector_size=16, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get word embeddings\n",
        "for word in words:\n",
        "    print(f\"Word: {word}, Embedding: {model.wv[word]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdAecclACaix"
      },
      "source": [
        "# **Contextual Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2-CPFe2wiY5",
        "outputId": "409ef393-1b51-4876-9198-0d2f6ea53936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGz8Umt-Cp5q",
        "outputId": "abd63ac6-472e-4c68-d314-c9e0d129d43f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Input\n",
        "sentence = \"Knowledge is power, but enthusiasm pulls the switch\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o7hU-d7FyCQX"
      },
      "outputs": [],
      "source": [
        "# Tokenize with fixed padding and truncation\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KVwCiEBTzFki"
      },
      "outputs": [],
      "source": [
        "# Run the model\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Get the embeddings (last_hidden_state)\n",
        "# These embeddings are part of the computation graph that PyTorch builds for calculating gradients.\n",
        "# detach() is used to remove these embeddings from the computation graph (Saving money and computational power).\n",
        "contextual_embeddings = outputs.last_hidden_state.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OILdtuik1-dw",
        "outputId": "83a87c1c-3a79-4633-9862-0d2add4bf3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contextual Embeddings : tensor([[[ 8.5051e-02,  8.8734e-02,  4.1578e-03,  ..., -2.3565e-01,\n",
            "           2.6658e-01,  4.9274e-01],\n",
            "         [ 2.4075e-01,  2.8072e-01,  5.9313e-01,  ...,  1.5525e-02,\n",
            "           9.3277e-01, -8.4173e-02],\n",
            "         [-2.4953e-01,  3.3956e-01,  5.4684e-01,  ..., -2.8481e-01,\n",
            "          -1.0912e-01,  8.0139e-01],\n",
            "         ...,\n",
            "         [ 3.5404e-04, -2.1287e-01,  7.7069e-01,  ..., -2.8971e-01,\n",
            "          -5.2090e-01,  5.3809e-01],\n",
            "         [-6.7954e-01, -9.3337e-01, -4.9169e-02,  ...,  4.2935e-01,\n",
            "           8.7299e-02, -6.5073e-02],\n",
            "         [ 9.0462e-01,  2.1638e-01,  1.6207e-01,  ...,  5.4705e-02,\n",
            "          -5.7996e-01, -6.7091e-01]]]) \n",
            " Shape: torch.Size([1, 10, 768])\n",
            "\n",
            "----------------------------------------------------------------\n",
            "\n",
            "Reduced Contextual Embedding : [[[-0.09891652  0.45738494 -0.21787538  0.26942688  0.09800021\n",
            "    0.4518376  -0.16058579  0.73541987  0.01510914  0.13160259\n",
            "   -0.59913373 -0.1023269  -0.15293786  0.04506467  0.25658676\n",
            "   -0.07748368]\n",
            "  [-0.2508249   0.28616983 -0.06487344  0.2583571   0.01367034\n",
            "    0.42675388 -0.23610552  0.10896514  0.11301275 -0.06013387\n",
            "   -0.7389797   0.07231037 -0.23736095  0.19857207  0.16240567\n",
            "   -0.16941968]\n",
            "  [-0.10160704 -0.14869246 -0.16643532 -0.28567222  0.05307804\n",
            "   -0.5465911   0.45373434  0.31334808  0.08234852  0.01970908\n",
            "    0.4333495   0.09814499 -0.29442877 -0.1007966  -0.17140608\n",
            "    0.27690864]\n",
            "  [-0.06006188 -0.06248644  0.03911356 -0.00353259  0.28344524\n",
            "    0.27100238 -0.05328572  0.03924841  0.05822942 -0.06222819\n",
            "   -0.4524312   0.0229983  -0.19469224  0.00524396  0.3063326\n",
            "   -0.15620138]\n",
            "  [ 0.7814245  -0.36337605  0.19054611 -0.2318931   0.25111085\n",
            "    0.07858491 -0.034707   -0.0200508  -0.0014648   0.30946568\n",
            "    0.05658183 -0.23150423 -0.01312995  0.59217626 -0.03063861\n",
            "   -0.23357186]\n",
            "  [ 0.13380466 -0.11646096  0.00120199 -0.27179837  0.39217037\n",
            "   -0.3716408   0.2929322   0.08075479  0.28932303  0.4479298\n",
            "    0.16302904  0.25987083 -0.19969317 -0.05866734  0.442673\n",
            "   -0.05647531]\n",
            "  [ 0.05243147 -0.02246766  0.33377764  0.19470301  0.03221649\n",
            "    0.31422442  0.141691    0.2020287   0.57481     0.15481773\n",
            "   -0.36340868  0.35594437  0.11623397 -0.19311276  0.49049783\n",
            "   -0.02840966]\n",
            "  [-0.20901448 -0.32764643 -0.25658482 -0.36291772  0.14582345\n",
            "   -0.42804193  0.5681719   0.21465349  0.01373225  0.07668953\n",
            "   -0.02161531  0.08736254 -0.10579028 -0.17595206  0.09635146\n",
            "    0.01522102]\n",
            "  [ 0.23996347  0.15787172  0.20392913 -0.07399068  0.63822824\n",
            "   -0.03456625  0.5889765   0.38974458 -0.31213725  0.17092627\n",
            "    0.35284278  0.3246621   0.00404185 -0.19582157  0.16104288\n",
            "   -0.35353115]\n",
            "  [ 0.6907573  -0.18482621  0.12340163 -0.06780148  0.36675394\n",
            "   -0.13462137 -0.06844614  0.14147373 -0.14175463  0.24751051\n",
            "    0.09472121  0.04599942 -0.12888117  0.5594103  -0.03855032\n",
            "   -0.2857374 ]]] \n",
            " Shape: (1, 10, 16)\n"
          ]
        }
      ],
      "source": [
        "# Check the shape\n",
        "print(f\"Contextual Embeddings : {contextual_embeddings} \\n Shape: {contextual_embeddings.shape}\")\n",
        "print(\"\\n----------------------------------------------------------------\\n\")\n",
        "# Dimensionality reduction to 16\n",
        "# We can use a linear transformation to reduce from 768 to 16 dimensions\n",
        "linear_layer = torch.nn.Linear(768, 16)\n",
        "contextual_embedding_reduced = linear_layer(contextual_embeddings).detach().numpy()\n",
        "\n",
        "# Check new shape\n",
        "print(f\"Reduced Contextual Embedding : {contextual_embedding_reduced} \\n Shape: {contextual_embedding_reduced.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etJeN5VkrEq8"
      },
      "source": [
        "### **Custom Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WpoT-61aGTeZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp50L6wwDcaa"
      },
      "source": [
        "### **Note:**\n",
        "**Random seed** is to ensure reproducibility. It initializes the random number generator in a fixed, predictable way so that:\n",
        "1.\t*Same Results Across Runs:* The same code with the same seed will always produce the same random numbers, embeddings, or model initialization.\n",
        "2.\t*Debugging:* It makes it easier to debug models since you can reproduce experiments consistently.\n",
        "3.\t*Experiment Comparison:* Ensures fair comparison between models by starting them with the same initial conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ad56G37Jr8kI"
      },
      "outputs": [],
      "source": [
        "# Set the random seed globally\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED) # for TensorFlow operations.\n",
        "np.random.seed(SEED) # for NumPy operations.\n",
        "random.seed(SEED) # for Python's built-in random module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ofyad1DmuSRQ"
      },
      "outputs": [],
      "source": [
        "sentence = 'Knowledge is power, but enthusiasm pulls the switch'\n",
        "\n",
        "# Tokenizing the sentence\n",
        "tokenizer = Tokenizer() # The Tokenizer is used to map each word in a text to a unique integer ID.\n",
        "tokenizer.fit_on_texts([sentence]) # The fit_on_texts() method learns the vocabulary and builds a dictionary mapping each word to a unique index.\n",
        "sequences = tokenizer.texts_to_sequences([sentence]) # The texts_to_sequences() method converts the actual text into sequences of integer IDs, where each ID corresponds to a word in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML_qLG_OmoYk",
        "outputId": "b793b00f-a68c-4d5a-ed0a-d0405e0551e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'knowledge': 1, 'is': 2, 'power': 3, 'but': 4, 'enthusiasm': 5, 'pulls': 6, 'the': 7, 'switch': 8}\n",
            "[[1, 2, 3, 4, 5, 6, 7, 8]]\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.word_index)\n",
        "print(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cXeqYQYNBeEW"
      },
      "outputs": [],
      "source": [
        "# Padding sequences to ensure uniform length\n",
        "max_length = 10 # max_length refers to the maximum number of tokens (words) in a sequence\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4xOmR6c9Cfu",
        "outputId": "ce67d284-04f2-46d4-a305-9fd90b8e094e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define the embedding layer\n",
        "embedding_dim = 16  # Dimension of the embedding vector\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
        "                            output_dim=embedding_dim,\n",
        "                            input_length=max_length,\n",
        "                            embeddings_initializer=tf.keras.initializers.RandomUniform(seed=SEED)) # Ensure deterministic initialization of embedding weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PLU7w9cbuq0w"
      },
      "outputs": [],
      "source": [
        "# Create a simple model to retrieve embeddings\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9ZgzYH4uutK",
        "outputId": "e56bf0bd-3a28-490e-aca6-785500786430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "Embeddings:\n",
            " [[[-2.17566844e-02 -1.58309937e-04  2.15458535e-02 -4.79797982e-02\n",
            "   -4.21401858e-02  1.26559399e-02  2.54998319e-02 -3.26794162e-02\n",
            "   -3.71287353e-02 -4.47329544e-02  4.42529209e-02 -2.69548055e-02\n",
            "   -2.24584341e-03 -2.53444910e-02  2.24576034e-02  2.69065835e-02]\n",
            "  [-2.17566844e-02 -1.58309937e-04  2.15458535e-02 -4.79797982e-02\n",
            "   -4.21401858e-02  1.26559399e-02  2.54998319e-02 -3.26794162e-02\n",
            "   -3.71287353e-02 -4.47329544e-02  4.42529209e-02 -2.69548055e-02\n",
            "   -2.24584341e-03 -2.53444910e-02  2.24576034e-02  2.69065835e-02]\n",
            "  [ 3.69108841e-03 -3.31294909e-02  2.80845910e-04 -3.00057419e-02\n",
            "   -4.64703105e-02 -1.87219605e-02 -2.56056711e-03  5.97994402e-03\n",
            "    3.23537253e-02  9.13666561e-03 -1.79730654e-02  2.62521394e-02\n",
            "   -3.74247432e-02  9.80285555e-03 -1.97220445e-02  3.52858938e-02]\n",
            "  [ 4.48628403e-02  2.60492601e-02 -1.85151920e-02  1.69372894e-02\n",
            "    4.13738564e-03  4.92382385e-02  1.43612884e-02 -4.83288169e-02\n",
            "    8.91736895e-03  1.92196108e-02  3.58860530e-02  3.30715440e-02\n",
            "    4.05373015e-02  3.08267809e-02  4.03654687e-02 -4.90951650e-02]\n",
            "  [ 2.67178155e-02 -4.92082611e-02  3.12481634e-02 -3.07811853e-02\n",
            "   -4.23606038e-02 -2.61145961e-02 -9.02746990e-03  3.26433517e-02\n",
            "    1.14559159e-02 -2.84583457e-02 -3.77620831e-02  3.43938954e-02\n",
            "   -2.14065313e-02  3.86576764e-02 -3.55095044e-02  4.97509874e-02]\n",
            "  [ 8.10357183e-03 -3.08075082e-02  5.04231453e-03  4.69853729e-03\n",
            "   -3.07155736e-02 -2.49023195e-02 -1.18499175e-02  4.38233949e-02\n",
            "    1.48274042e-02 -2.08305605e-02 -4.53543663e-03 -1.99659113e-02\n",
            "   -1.13038532e-02  3.26633453e-05  4.44479249e-02 -3.37134972e-02]\n",
            "  [-9.48520750e-03 -2.77611017e-02 -2.70486362e-02  2.32548006e-02\n",
            "    3.06820869e-03 -1.39692053e-02 -3.87148857e-02  1.46786459e-02\n",
            "   -1.30283125e-02 -2.00068951e-03  3.41388620e-02 -4.98183966e-02\n",
            "   -2.13198904e-02  8.07253271e-03  1.75009705e-02  1.19205564e-03]\n",
            "  [-1.95000768e-02  3.19698565e-02  7.39456341e-03 -2.87669655e-02\n",
            "   -4.75714803e-02 -4.69553955e-02 -3.45160253e-02 -2.45424155e-02\n",
            "    3.68144400e-02  1.89559124e-02  2.50417031e-02  2.44459994e-02\n",
            "   -4.47954647e-02 -1.67210586e-02  1.54439323e-02 -1.78523771e-02]\n",
            "  [-1.39902905e-03  4.64007370e-02 -4.02627140e-03 -4.70761918e-02\n",
            "   -3.13098915e-02  2.09701918e-02  2.17120163e-02  3.46404798e-02\n",
            "    1.10641494e-02  3.70225571e-02 -6.86774403e-03 -3.36959213e-03\n",
            "   -3.33679914e-02  3.07364799e-02  9.68359411e-04 -1.15291029e-03]\n",
            "  [-2.11157333e-02  4.94057871e-02  4.73052971e-02 -3.45913395e-02\n",
            "   -4.84765172e-02  2.78252475e-02 -2.93010715e-02  2.21979059e-02\n",
            "    7.31457397e-03 -4.77203615e-02  4.52910177e-02  5.24521992e-03\n",
            "    2.16374546e-03 -2.19255220e-02 -4.25082445e-03 -4.91667986e-02]]] \n",
            " (1, 10, 16)\n"
          ]
        }
      ],
      "source": [
        "# Get embeddings for the sentence\n",
        "embeddings = model.predict(padded_sequences)\n",
        "print(f\"Embeddings:\\n {embeddings} \\n {embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMjnicFw3289",
        "outputId": "c8b6f22b-0edb-4eb6-e969-b5de82d1042c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 16)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings = embeddings.reshape(10, 16)\n",
        "\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
